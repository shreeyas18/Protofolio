# 🔍 ML Classification Models – Naïve Bayes, KNN, Decision Tree

**Tools:** Python, scikit-learn  
**Skills:** Classification, Supervised Learning, Model Evaluation, Confusion Matrix

---

## ✅ About the Project  
This set of labs focused on building and comparing three core classification models: **Naïve Bayes**, **k-Nearest Neighbors**, and **Decision Trees**. The goal was to learn how each model makes decisions, how to interpret predictions, and how to assess performance using various metrics.

---

## ❓ The Problem  
Given labeled datasets, how can we predict class membership (e.g., spam vs. not spam, disease vs. healthy)? What’s the trade-off between model complexity and performance?

---

## 📈 Results & Highlights  
- Built and evaluated 3 classifiers using `scikit-learn`  
- Compared model performance using **confusion matrix**, **accuracy**, and **precision/recall**  
- **Naïve Bayes** showed high performance on clean, categorical data  
- **Decision Tree** visualized the decision-making process with interpretable splits  
- **KNN** struggled with noisy data but performed well with optimal `k` selection  
- Learned model strengths and use cases through experimentation

---

📎 **Files in this folder:**  
- `Lab 2 - Naïve Bayes Classification.pdf`  
- `Lab 3 – Decision Tree and KNN.pdf`  
- Python scripts
- transfusions.csv Data set

---

## 🔗 View in Portfolio  
[Read Project Summary on Portofolio](https://transparent-rook-33b.notion.site/Hey-I-m-Shreeya-Sampat-1c1c4f21290c80a7a02ef878ea11233c?p=1c1c4f21290c81d69a00c66c41b044d5&pm=c)
