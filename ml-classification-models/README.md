# ğŸ” ML Classification Models â€“ NaÃ¯ve Bayes, KNN, Decision Tree

**Tools:** Python, scikit-learn  
**Skills:** Classification, Supervised Learning, Model Evaluation, Confusion Matrix

---

## âœ… About the Project  
This set of labs focused on building and comparing three core classification models: **NaÃ¯ve Bayes**, **k-Nearest Neighbors**, and **Decision Trees**. The goal was to learn how each model makes decisions, how to interpret predictions, and how to assess performance using various metrics.

---

## â“ The Problem  
Given labeled datasets, how can we predict class membership (e.g., spam vs. not spam, disease vs. healthy)? Whatâ€™s the trade-off between model complexity and performance?

---

## ğŸ“ˆ Results & Highlights  
- Built and evaluated 3 classifiers using `scikit-learn`  
- Compared model performance using **confusion matrix**, **accuracy**, and **precision/recall**  
- **NaÃ¯ve Bayes** showed high performance on clean, categorical data  
- **Decision Tree** visualized the decision-making process with interpretable splits  
- **KNN** struggled with noisy data but performed well with optimal `k` selection  
- Learned model strengths and use cases through experimentation

---

ğŸ“ **Files in this folder:**  
- `Lab 2 - NaÃ¯ve Bayes Classification.pdf`  
- `Lab 3 â€“ Decision Tree and KNN.pdf`  
- Python scripts
- transfusions.csv Data set

---

## ğŸ”— View in Portfolio  
[Read Project Summary on Portofolio](https://transparent-rook-33b.notion.site/Hey-I-m-Shreeya-Sampat-1c1c4f21290c80a7a02ef878ea11233c?p=1c1c4f21290c81d69a00c66c41b044d5&pm=c)
